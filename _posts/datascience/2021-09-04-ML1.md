---
layout: post
title: '기계학습_Machine Learning?'
subtitle: '1주차_기계학습이란, 용어정리'
date: 2021-09-04 15:50:00 +0900
use_math: true
categories: [datascience]
---

**기계학습**: 명시적인 프로그래밍 없이 컴퓨터가 학습하게 하는 능력을 갖추게 하는 연구분야  
<div style="text-align: right"> -아서 새뮤얼  </div>

**기계학습과 통계적 학습**  
 -기계학습은 인공지능연구의 한 분야, 통계적 학습은 통계학의 한 분야  
 -구분하는 것은 의미 없으나 기계학습은 large scale의 응용분야에 많이 사용, 예측과 그 결과의 정확성을 좀 더 강조, 통계적 학습은 모델의 해석가능성, 추론과 불확실성에 대한 연구를 강조  

**데이터 마이닝**: 기계학습을 통해 대용량 데이터를 분석, 겉으로 안보이는 패턴 찾는 것  

**데이터 세트:** 수집된 데이터 기록의 집합  
**사례, 샘플:** 각 기록은 하나의 대상에 대한 묘사  
**속성, 특성, 예측 변수:** 색깔, 꼭지모양 같은 대상의 성질을 반영하는 것/ 속성값: 속성이 취할 수 있는 값  
**차원:** 고려하는 속성 종류의 개수, n  
**특성벡터:** 좌표공간 $R^n$ 을 생각할 때, 속성값을 숫자로 나타내고 차례로 배열하여 벡터로 나타낸 것.  
**입력공간, 샘플공간:** 특성벡터들의 집합  

**학습(learning), 훈련(training):** 데이터를 통해 모델을 만들어 가는 과정  
**가설(hypothesis):** 학습 모델은 데이터 속에 잠재된 어떤 규칙에 대응하여 세운 것  

>>학습의 목표는 데이터를 통해 가설(학습 모델)을 세우고 잠재되어 있는 규칙을 찾거나 가까이 가는 것  

**레이블**: 훈련 데이터에 대한 결과 정보/   레이블 공간, 출력공간: 레이블들의 집합  

**예측**: 학습한 모델을 활용하여 어떤 결과에 대해 판단하는 것   

- f(가설 공간) 에 대한 예측과 추론의 차이  
> - 예측: f를 일종의 블랙박스로 취급 
> - 추론: f를 이해하는데 중점  

**분류 문제**: 예측하려는 값이 이산적인 학습 문제 +다항 분류 문제  
**회귀 문제**: 예측하려는 값이 연속적인 학습 문제  

**지도학습**: 훈련 데이터에 레이블이 있음 ex) 분류, 회귀  
-분류 회귀와 관련된 알고리즘: k-최근접 이웃, 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정 트리와 랜덤 포레스트, 신경망  

**비지도학습**: 훈련 데이터에 레이블이 없음, ex) 군집화  
-군집화 학습 알고리즘: k-means, DBSCAN, 이상치 탐지, 특이치 탐지, 원 클래스 SVM   

**시각화(visualization)와 차원 축소(dimensionality reduction):** 너무 많은 정보를 잃지 않으면서 차원이 높은 데이터의 차원을 낮추는 것  

-차원 축소와 관련된 학습 알고리즘: 주성분 분석(PCA), 커널 PCA, 지역적 선형 임베딩(LLE) , t-SNE   

**준지도 학습:** 데이터 중 일부만 레이블이 있는 경우  

**강화 학습:** 에이전트라 부르는 시스템이 환경을 관찰해서 행동을 실행하고 그 결과로 보상을 받음, 시간이 지나면서 가장 큰 보상을 얻기 위한 정책이라고 부르는 최상의 전략을 스스로 학습  
Ex) 알파고, 자율 주행  
	
일반화: 학습된 모델이 새로운 데이터에 적용되고 좋은 성능을 내는 것  
 -테스트 데이터를 이용 일반화 능력을 확인  

기계학습의 귀납적 편향: 유한 개의 훈련 데이터를 이용하여 가설을 선택할 때 반드시 어떤 편향을 가지고 있어야 정확하다고 여겨질 수 있는 모델을 생성하는 것이 가능  

오컴의 면도날: 만약 다수의 가설이 관측된 것과 일치한다면, 가장 간단한 것 선택해야 한다.  

No free lunch theorem: 모든 잠재적인 문제를 고려한다면 모든 학습 알고리즘이 동등함을 보일 수 있다. 즉 어떤 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없다는 의미.  
모든 모델을 평가하는 것은 불가능하니 데이터에 관한 타당한 가정- 적절한 모델 몇 가지를 평가- 최종 선택  

**기계학습 시스템이 어떻게 일반화되는가에 따라 분류:**  
-사례 기반 학습: 두 샘플 사이의 다양한 유사도를 이용하여 일반화(예측)  
 ex) k-최근접 이웃: 새로운 샘플과 훈련 데이터 사이의 거리를 비교하는 방식  

-모델 기반 학습: 샘플들의 모델을 만들어서 예측에 이용하는 방법으로 일반화(추론), 즉 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하는 방식  

**기계 학습의 주요과제**  
:기계학습의 핵심이 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는 것이므로 문제가 될 수 있는 두 가지는 ‘나쁜 알고리즘’, ‘나쁜 데이터’  
- 충분하지 않은 양의 훈련 데이터  
- 대표성이 없는 훈련 데이터: 샘플링 편향의 대표적인 예 ex) 랜던과 루즈벨트의 미국 대통령 선거 여론 조사)  
- 낮은 품질의 데이터: 일부 샘플이 이상치이거나 일부 샘플에 특성 몇 개가 빠진 경우  
- 관련 없는 특성: 특성 공학(feature engineering)을 통해 극복  
	    - 특성 선택: 가지고 있는 특성 중 유용한 특성을 선택  
	    - 특성 추출: 특성을 결합하여 더 유용한 특성을 만듦  

-훈련 데이터의 과대적합: 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 것으로 다음과 같은 해결 방법을 이용  
- 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄여서 해결 시도  
- 훈련 데이터를 더 모아서 해결 시도  
- 오류 데이터 수정, 이상치 제거 등을 통해 훈련 데이터의 잡음 제거  
- 모델에 제약을 가해 단순화시켜 해결 시도, 모델에 제약을 가하는 것: 규제  

하이퍼파라미터: 학습하는 동안 적용할 규제의 양을 조절하는 파라미터/모델하고는 상관없음  

훈련 데이터의 과소적합: 모델이 너무 단순해서 데이터에 내재된 구조를 학습하지 못하는 것으로 다음과 같은 해결 방법  
- 모델 파라미터가 더 많은 복잡한 모델 선택  
- 더 좋은 특성 추가하여 해결 시도  
- 모델의 제약을 완화시켜 해결 시도  

**모델의 평가와 선택**  
- 모델이 새로운 샘플에 얼마나 잘 일반화될 지 아는 것은 새로운 샘플에 실제로 적용해 보는 것  
- 훈련 데이터를 훈련 세트와 테스트 세트로 나눈 다음, 훈련 세트를 사용해 모델을 학습시키고 테스트 세트에 대한 오류 비율을 일반화 오차에 대한 추정치로 사용  
- 선택한 모델에 대한 일반화 오차 예측: 테스트 세트를 이용하여 일반화 오차의 추정치 계산  
- 동일한 문제에 대해 여러 모델 중 일반화가 가장 잘 될 것으로 기대되는 모델을 선택하는 방법  

-홀드아웃 검증(테스트 세트와 분리한 훈련 세트가 충분히 클 때): 데이터 세트를 훈련세트, 검증 세트, 테스트 세트 (ex: 80, 10, 10)   
- 교차 검증(테스트 세트와 분리한 훈련 세트가 충분히 크지 않을 때):   
훈련 세트에서 작은 검증 세트 여러 개를 중복되지 않게 지정- 각 검증 세트마다 자신을 제외한 나머지 훈련 세트의 샘플로 모델 훈련- 학습된 각 모델마다 검증 세트 별 평가를 평균-최종 평가를 구하고 비교- 최종 선택 모델 선택  
- k겹 교차 검증: 데이터 세트에서 테스트 세트 뺴고 나머지를 k개로 나눈 다음 각자 1개씩 빼고 k번 학습하고 검증 세트 별 평가를 평균 내어 제일 오차가 적은 모델 선택    

Reference:
-기계학습_하길찬 교수님 수업을 듣고 학습한 내용입니다. 
