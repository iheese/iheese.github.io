---
layout: post
title: '기계학습_ROC와 AUC'
subtitle: '6-1주차_AUC, ROC, PR곡선'
date: 2021-10-06 18:30:00 +0900
categories: 'ML'
use_math: true
---

- 앞 ML5-2 주차와 이어지는 내용입니다. 

  

## 분류기에 대한 다양한 성능 평가5 :  ROC와 AUC

- **ROC(Receiver Operating Characteristic) 곡선**:

  이진 분류기(레이블이 두 가지)의 성능을 평가하기 위해 사용되는 곡선으로 **거짓 양성 비율(FPR:False Positive Rate)**에 대한 **진짜 양성 비율(TPR:True Positive Rate)(재현율)**을 나타낸 곡선

- **거짓 양성 비율**은 양성으로 잘못 분류된 음성 샘플의 비율. 이는 1에서 음성으로 정확하게 분류한 음성 샘플의 비율인 **진짜 음성 비율 (TNR)**을 뺀 값
  $$
  \text{FPR}= \dfrac{\text{FP}}{\text{TN}+\text{FP}} = 1-\dfrac{\text{TN}}{\text{TN}+\text{FP}}=1-\text{TNR}
  $$

- TNR을 **특이도(specificity)**라고도 함 (따라서 ROC 곡선은 `민감도(재현율)`에 대한 `1-특이도`의 그래프
-  완벽한 분류기는 ROC의 AUC가 1이고, 완전히 랜덤한 분류기에 대한 AUC는 0.5 

- **ROC에 대한 AUC의 확률적 의미:**

랜덤하게 뽑은 양성 샘플의 score(우리 예의 경우에는 레이블이 1이 될 확률)가 랜덤하게 뽑은 음성 샘플의 score보다 클 확률 

![ROC곡선](/img/posts/ML6/rocauc.png)

```python
from sklearn.metrics import roc_auc_score #AUC를 구할 수 있다. 
from sklearn.metrics import roc_curve #임계값에 대한 FPR, TPR 계산 

auc = roc_auc_score(y_train, y_val_prob1)

fpr, tpr, thresholds = roc_curve(y_train, y_val_prob1)
plt.figure(figsize=(5,5))
plt.plot(fpr, tpr, linewidth=1)
plt.plot([0,1], [0,1], 'k--',linewidth=1)
plt.grid(True)
plt.xlabel("FPR", fontsize=10)
plt.ylabel("TPR", fontsize=10)
plt.text(0.6,0.2, f"AUC={auc : .2f}")
```



![AUC](/img/posts/ML6/auc.png)



## 분류기에 대한 다양한 성능 평가 6:  ROC곡선과  PR곡선

- PR 곡선:

양성 클래스가 드물거나, 거짓음성보다 거짓 양성이 더 중요한 의미 가질 때 사용

- 그 외에는 ROC곡선 사용

- 앞의 예시 PimalndiansDiabete 데이터 셋에서 양성 샘플의 개수가 음성 샘플에 비해 적어 ROC곡선, AUC는 나쁘지 않아 보이지만 PR곡선은 개선의 여지가 많이 보임.
- 상황에 맞는 성능 평가 기준을 사용하는 것이 중요하다. 